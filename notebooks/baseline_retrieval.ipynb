{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose:\n",
    "\n",
    "Using the retrieval model for a response to query, this notebook follows the recommendation of a popular paper for baselining a more advanced approach.\n",
    "\n",
    "Replicate the TF-IDF Baseline Evaluation but on my data: https://github.com/dennybritz/chatbot-retrieval/blob/master/notebooks/TFIDF%20Baseline%20Evaluation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.15 s, sys: 265 ms, total: 1.41 s\n",
      "Wall time: 1.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load Data\n",
    "train_df = pd.read_pickle(\"../../data/option3_data/train_df.pickle\")\n",
    "test_df = pd.read_csv(\"../../data/option3_data/test.csv\")\n",
    "val_df = pd.read_csv(\"../../data/option3_data/valid.csv\")\n",
    "#test_df = pd.read_pickle(\"../../data/option3_data/test.pickle\")\n",
    "y_test = np.zeros(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>label</th>\n",
       "      <th>utterance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>That's a good idea, but I'm still too embarras...</td>\n",
       "      <td>1</td>\n",
       "      <td>Obgyns deal with WAY worse stuff than this on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>That's a good idea, but I'm still too embarras...</td>\n",
       "      <td>0</td>\n",
       "      <td>You need to be evaluated by both mental health...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>That's a good idea, but I'm still too embarras...</td>\n",
       "      <td>0</td>\n",
       "      <td>As everyone else has said, yes you are doing y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>That's a good idea, but I'm still too embarras...</td>\n",
       "      <td>0</td>\n",
       "      <td>Hypertrophic scarring. [More info and possible...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>That's a good idea, but I'm still too embarras...</td>\n",
       "      <td>0</td>\n",
       "      <td>okay, good to know. Thank you for your response</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              context  label  \\\n",
       "20  That's a good idea, but I'm still too embarras...      1   \n",
       "21  That's a good idea, but I'm still too embarras...      0   \n",
       "22  That's a good idea, but I'm still too embarras...      0   \n",
       "23  That's a good idea, but I'm still too embarras...      0   \n",
       "24  That's a good idea, but I'm still too embarras...      0   \n",
       "\n",
       "                                            utterance  \n",
       "20  Obgyns deal with WAY worse stuff than this on ...  \n",
       "21  You need to be evaluated by both mental health...  \n",
       "22  As everyone else has said, yes you are doing y...  \n",
       "23  Hypertrophic scarring. [More info and possible...  \n",
       "24    okay, good to know. Thank you for your response  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_recall(y, y_test, k=1):\n",
    "    num_examples = float(len(y))\n",
    "    num_correct = 0\n",
    "    for predictions, label in zip(y, y_test):\n",
    "        if label in predictions[:k]:\n",
    "            num_correct += 1\n",
    "    return num_correct/num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_random(context, utterances):\n",
    "    return np.random.choice(len(utterances), 4, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall @ (1, 10): 0.100675\n",
      "Recall @ (2, 10): 0.2\n",
      "Recall @ (5, 10): 0.399273\n",
      "Recall @ (10, 10): 0.399273\n",
      "CPU times: user 2.63 s, sys: 70.7 ms, total: 2.7 s\n",
      "Wall time: 2.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Evaluate Random predictor\n",
    "y_random = [predict_random(test_df.context[x], test_df.iloc[x,1:].values) for x in range(len(test_df))]\n",
    "for n in [1, 2, 5, 10]:\n",
    "    print(\"Recall @ ({}, 10): {:g}\".format(n, evaluate_recall(y_random, y_test, n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFIDFPredictor:\n",
    "    def __init__(self):\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "\n",
    "    def train(self, data):\n",
    "        self.vectorizer.fit(np.append(data.context.values,data.utterance.values))\n",
    "\n",
    "    def predict(self, context, utterances):\n",
    "        # Convert context and utterances into tfidf vector\n",
    "        vector_context = self.vectorizer.transform([context])\n",
    "        vector_doc = self.vectorizer.transform(utterances)\n",
    "        # The dot product measures the similarity of the resulting vectors\n",
    "        result = np.dot(vector_doc, vector_context.T).todense()\n",
    "        result = np.asarray(result).flatten()\n",
    "        # Sort by top results and return the indices in descending order\n",
    "        return np.argsort(result, axis=0)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall @ (1, 10): 0.476141\n",
      "Recall @ (2, 10): 0.570431\n",
      "Recall @ (5, 10): 0.722859\n",
      "Recall @ (10, 10): 1\n",
      "CPU times: user 1min 37s, sys: 2.71 s, total: 1min 39s\n",
      "Wall time: 1min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Evaluate TFIDF predictor\n",
    "pred = TFIDFPredictor()\n",
    "pred.train(train_df)\n",
    "y = [pred.predict(test_df.context[x], test_df.iloc[x,1:].values) for x in range(len(test_df))]\n",
    "for n in [1, 2, 5, 10]:\n",
    "    print(\"Recall @ ({}, 10): {:g}\".format(n, evaluate_recall(y, y_test, n)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Very surprising, because these are very similar metrics to what was first reported in paper. Especially given the performance of random selection.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"../../data/reddit_may_2015_embeddings/model_full_reddit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cereal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/austinpowell/Google_Drive/kp_datascience/virtual_envs/nlp-env/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.doesnt_match(\"breakfast cereal dinner lunch\".split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/austinpowell/Google_Drive/kp_datascience/virtual_envs/nlp-env/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/austinpowell/Google_Drive/kp_datascience/virtual_envs/nlp-env/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('reedit', 0.7281540036201477),\n",
       " ('fph', 0.7037860155105591),\n",
       " ('twitter', 0.7018535137176514),\n",
       " ('chan', 0.6998030543327332),\n",
       " ('facebook', 0.6992213726043701),\n",
       " ('sub', 0.6870619058609009),\n",
       " ('forum', 0.6837552189826965),\n",
       " ('neogaf', 0.6561684608459473),\n",
       " ('tia', 0.6557859182357788),\n",
       " ('srd', 0.6524701118469238)]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['reddit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-env",
   "language": "python",
   "name": "nlp-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
