{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose:\n",
    "\n",
    "Load data and create query/response pairs in different ways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Custom\n",
    "from processing import tag_utterances\n",
    "from processing import load_sem_types\n",
    "from processing import DataPipeline\n",
    "pd.set_option('display.max_columns', 500) # more columns displayed at once\n",
    "\n",
    "# Set path for importing data\n",
    "data_instance = DataPipeline(comments_path = '../data/reddit_comments_askDocs_2014_to_2018_03.gz',\n",
    "                            posts_path = '../data/original_posts_under_askDocs_subreddit_id.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a lot that could be done with formatting the data for training conversations:\n",
    "\n",
    "* Option 1: All responses are equal\n",
    "    * Treat every thread as a conversation\n",
    "    * Every comment in the thread as a response to the original AskDocs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: All responses are equal\n",
    "\n",
    "* Each title of the thread is listed as the question \n",
    "* Every comment in that thread is listed as the answer\n",
    "* The comment of the first query/post asked by the original author is ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comments Table Shape: (557648, 24)\n",
      "Posts table shape: (43615, 35)\n",
      "30710\n",
      "Final combined table shape: (139535, 28)\n",
      "Count of threads\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0    108825\n",
       "1.0     30710\n",
       "Name: is_thread_start, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = data_instance.load_full_thread()\n",
    "\n",
    "print('\\nCount of threads:')\n",
    "df['is_thread_start'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 25s, sys: 2.38 s, total: 6min 27s\n",
      "Wall time: 6min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "list_of_threads = df['link_id_short'].unique().tolist()\n",
    "\n",
    "query = []\n",
    "answer = []\n",
    "\n",
    "# loop through all threads\n",
    "for thread in list_of_threads:\n",
    "    try:\n",
    "        df_subset = df.loc[df['link_id_short']==thread]\n",
    "        # assert there is one poster\n",
    "        assert sum(df_subset['is_thread_start'].unique()) == 1\n",
    "\n",
    "        thread_author = str(df_subset.loc[df_subset['is_thread_start']==1]['author'].unique()[0]).strip()\n",
    "        thread_question = str(df_subset.loc[df_subset['is_thread_start']==1]['body'][0]).strip()\n",
    "\n",
    "\n",
    "        thread_title = df_subset.title[df_subset.title.notnull()][0]\n",
    "\n",
    "        try:\n",
    "            thread_title_short = df_subset.url.unique()[1].split('/')[-2]\n",
    "        except:\n",
    "            thread_title_short = df_subset.url.unique()[1]\n",
    "\n",
    "\n",
    "        thread_readers = df_subset.loc[df_subset['parent_id_short']==thread].author.tolist()\n",
    "\n",
    "        if False:\n",
    "            print('thread:',thread)\n",
    "            print('thread_author:',thread_author)\n",
    "            print('url:',df_subset.url.unique()[1])\n",
    "            print('thread_title short:',thread_title_short)\n",
    "            print('thread_title:',thread_title)\n",
    "            print('thread_readers:',thread_readers)\n",
    "\n",
    "        for index,row in df_subset.loc[df_subset['is_thread_start']!=1].iterrows():\n",
    "            query.append({'author':thread_author,'reader':row['author'],'utterance':thread_title})\n",
    "            answer.append({'author':row['author'], 'reader': thread_author,'utterance':row['body']})\n",
    "    except:\n",
    "        print(thread)\n",
    "        \n",
    "assert len(query)==len(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(zip(query,answer),open( '../data/all_responses_equal.p', \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of hand tonsil infection. Help!\n",
      "\n",
      "Out of hand tonsil infection. Help!\n",
      "\n",
      "Out of hand tonsil infection. Help!\n",
      "\n",
      "Out of hand tonsil infection. Help!\n",
      "\n",
      "Out of hand tonsil infection. Help!\n",
      "\n",
      "Out of hand tonsil infection. Help!\n",
      "\n",
      "Out of hand tonsil infection. Help!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, row in df_subset.iterrows():\n",
    "    print(df_subset.title[df_subset.title.notnull()][0])\n",
    "    #print(row['url'],row['body'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: {'author': 'dpeters14fuck', 'reader': 'ebast', 'utterance': 'Out of hand tonsil infection. Help!'}\n",
      "A: {'author': 'ebast', 'reader': 'dpeters14fuck', 'utterance': 'Well, then just be careful and try to avoid any kind of abdominal trauma. Best of luck! Get better soon so you can enjoy your vacations :)'}\n",
      "\n",
      "Q: {'author': 'dpeters14fuck', 'reader': 'dpeters14fuck', 'utterance': 'Out of hand tonsil infection. Help!'}\n",
      "A: {'author': 'dpeters14fuck', 'reader': 'dpeters14fuck', 'utterance': \"Thanks for the advice and well wishing! It's now wednesday and I've been all good at work so I guess as long as I'm not straining myself too much I'll be all good\"}\n",
      "\n",
      "Q: {'author': 'dpeters14fuck', 'reader': 'ebast', 'utterance': 'Out of hand tonsil infection. Help!'}\n",
      "A: {'author': 'ebast', 'reader': 'dpeters14fuck', 'utterance': \"You're welcome :) well, that's hard to say actually. Contact sports are like the classic thing you tell patients not to do because the spleen gets a little bigger during mono. I'd say you give it some time of rest, if possible. Didn't the doctors give you like a 'no working for x time' paper? I don't know the thing's name in english!\"}\n",
      "\n",
      "Q: {'author': 'dpeters14fuck', 'reader': 'ebast', 'utterance': 'Out of hand tonsil infection. Help!'}\n",
      "A: {'author': 'ebast', 'reader': 'dpeters14fuck', 'utterance': \"I'd say that's probably mononucleosis (i'm a last year medical student). Large tonsils. worse than any strep you've ever get, no effect with amoxicillin, trouble breathing and large painful lymph nodes. Yep, I'd say that. If so it doesn't really have a specific treatment except for acetaminophen and/or ibuprofen for fever and pain but you should get tested anyway. Also sometimes people with mono will get a skin rash when on amoxicillin. But not every one get's it. You should see a doc to confirm this and rule out other stuff like tonsil abcess or so.\"}\n",
      "\n",
      "Q: {'author': 'dpeters14fuck', 'reader': 'dpeters14fuck', 'utterance': 'Out of hand tonsil infection. Help!'}\n",
      "A: {'author': 'dpeters14fuck', 'reader': 'dpeters14fuck', 'utterance': \"I returned to urgent care when I couldn't breathe through my mouth at all the next day. The doctor suspected an abscess and said I should head to the ER to see if they would drain it. After being hooked up to an IV, given more antibiotics, and a steroid injection(which was all I asked for in the first place at urgent care for the swelling), and a CT scan, it turns out it is Mono after all(which is also surprising they didn't test for it at urgent care).  Anyway, I can at least eat soft foods now which is good. \\n\\n\\nAlso, I'm well aware I should avoid contact sports with mono due to risk of a ruptured spleen, but am I still able to lift heavy weights? At work I have to haul coffee sacks weighing anywhere from 150-200lbs so I want to be sure that wouldn't increase the risk\\n\\n\\nEdit: thanks for the reply btw you were spot on haha\"}\n",
      "\n",
      "Q: {'author': 'dpeters14fuck', 'reader': 'dpeters14fuck', 'utterance': 'Out of hand tonsil infection. Help!'}\n",
      "A: {'author': 'dpeters14fuck', 'reader': 'dpeters14fuck', 'utterance': \"I didn't get anything about taking days off work, however my employers are pretty flexible so if I do need time off I can just ask for it. On the other hand I don't feel all that terrible aside from a sore throat and I'd prefer not to take days off if I don't absolutely have to since I'll be out of the country in 2 weeks anyway \"}\n",
      "\n",
      "Number of Q/A: 6\n"
     ]
    }
   ],
   "source": [
    "for idx in range(len(query)):\n",
    "    print(\"Q:\", query[idx])\n",
    "    print(\"A:\", answer[idx])\n",
    "    print()\n",
    "print('Number of Q/A:',len(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I just got them today, and it was my first time wearing contacts in a few years. They weren't moving every time I blinked, but occasionally, maybe once every few minutes. Then after a while, I noticed it happening much less often, although it still happened occasionally. Maybe because I was distracted, I wasn't focusing on it as much. Maybe I was blinking less? I was playing a video game/watching TV for a while, and it was much better. \n",
      "\n",
      "\n",
      "Other than that, no reddness or discomfort from them. Tomorrow I'm going to take them for a spin during the day and wear them a little longer. (i'll bring my glasses just in case though).\n",
      "Does it happen every time you blink? How many days have you been wearing them? They do take a while to get used to although if they are moving every time you blink they may not be the best fit for you. Astigmatism is harder to fit then regular prescriptions as the lens or the cornea is irregularly shaped. \n",
      "\n",
      "If your eyes become slightly red or irritated from the lenses I would definitely tell your optometrist, and if this happens stop wearing the contacts ASAP. If not I would recommend just mentioning it them anyway so they can have a quick look for themselves using the slit lamp.   \n",
      "Not sure if the medical stuff is needed for eye related questions but:\n",
      "\n",
      "female\n",
      "\n",
      "20's\n",
      "\n",
      "No preexisting conditions (other than eye stuff)\n",
      "\n",
      "have worn glasses for almost 20 years\n",
      "\n",
      "**mild astigmatism**\n",
      "\n",
      "\n",
      "So today I went for my regular eye exam, and decided to forgo a new set of glasses and opt for contacts instead. Now, I've tried contacts before, but I never stuck with them due to general laziness and genuinely liking glasses, however, it's gotten to the point that glasses are a bit of a nuisance for me, as well.\n",
      "\n",
      "I have a mild astigmatism, but not bad enough to warrant corrective contact lenses, at least yet. I'm currently wearing a trial pair of Accuvue contacts that are meant to last 2 weeks. Anyway, I'm going about my business at home while getting used to the new contacts, and I'm noticing every so often, a lens may shift slightly in my eye causing slight discomfort or blurring. I can blink it back into place easily, but I'm not sure if that's a normal sensation or if I should bring it up with my eye doctor. I'm also wondering if this is just a normal thing that happens with astigmatism when you don't have corrective lenses. It's also possible I'm hyper aware of it because it's a fairly novel sensation. Other than the occasional blurring I can see clearly, and they aren't uncomfortable. \n",
      "\n",
      "So what do you think? Will I get used to it? Am I doing something wrong? Either way, I'll be back at the eye doctor in few days to pick up another sample of daily disposables.\n",
      "\n",
      "Thanks! \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index,row in df_subset.iterrows():\n",
    "    print(row['body'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: Every comment is a question and answer\n",
    "\n",
    "There might be a sub-option here: We get more data if we don't join with posts (i.e. the post that started the thread). Each post that had the original post as its parent_id would become the top level but be eliminated if it did not have post response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comments Table Shape: (557648, 24)\n",
      "Posts table shape: (43615, 35)\n",
      "30710\n",
      "Final combined table shape: (139535, 28)\n"
     ]
    }
   ],
   "source": [
    "df = data_instance.load_full_thread()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link_id_short</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>parent_id_short</th>\n",
       "      <th>post_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1662</th>\n",
       "      <td>37o1az</td>\n",
       "      <td>t3_37o1az</td>\n",
       "      <td>37o1az</td>\n",
       "      <td>cvkbr58</td>\n",
       "      <td>cvkbr58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663</th>\n",
       "      <td>37o1az</td>\n",
       "      <td>t1_cvnw8ly</td>\n",
       "      <td>cvnw8ly</td>\n",
       "      <td>cvnwkg4</td>\n",
       "      <td>cvnwkg4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>3exs68</td>\n",
       "      <td>t3_3exs68</td>\n",
       "      <td>3exs68</td>\n",
       "      <td>cwphyrq</td>\n",
       "      <td>cwphyrq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2549</th>\n",
       "      <td>399nb8</td>\n",
       "      <td>t1_cw2sr75</td>\n",
       "      <td>cw2sr75</td>\n",
       "      <td>cw2svpt</td>\n",
       "      <td>cw2svpt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2550</th>\n",
       "      <td>399nb8</td>\n",
       "      <td>t1_cw1xikq</td>\n",
       "      <td>cw1xikq</td>\n",
       "      <td>cw2fe2o</td>\n",
       "      <td>cw2fe2o</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     link_id_short   parent_id parent_id_short  post_id       id\n",
       "1662        37o1az   t3_37o1az          37o1az  cvkbr58  cvkbr58\n",
       "1663        37o1az  t1_cvnw8ly         cvnw8ly  cvnwkg4  cvnwkg4\n",
       "2156        3exs68   t3_3exs68          3exs68  cwphyrq  cwphyrq\n",
       "2549        399nb8  t1_cw2sr75         cw2sr75  cw2svpt  cw2svpt\n",
       "2550        399nb8  t1_cw1xikq         cw1xikq  cw2fe2o  cw2fe2o"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# heres the situation we're dealing with in terms of looking at which post belongs to which\n",
    "df[['link_id_short','parent_id','parent_id_short','post_id','id']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30710\n"
     ]
    }
   ],
   "source": [
    "# all original posts\n",
    "all_threads = df['link_id_short'].unique().tolist()\n",
    "print(len(all_threads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num total posts: (84, 28)\n",
      "Num first responses: 21\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_columns = ['link_id_short','parent_id','parent_id_short','post_id','id']\n",
    "# example link_id 37o1az\n",
    "df_example = df[df['link_id_short'] == '37o1az']\n",
    "\n",
    "print('Num total posts:',df_example.shape)\n",
    "print('Num first responses:',sum(df_example['parent_id_short'] == df_example['link_id_short']))\n",
    "\n",
    "# original post\n",
    "df_example[df_example['body'].str.contains(\"Pertinent facts\")][imp_columns]\n",
    "\n",
    "query = []\n",
    "response = []\n",
    "\n",
    "qr_pair = []\n",
    "# Append top query\n",
    "query_id = df_example[df_example['parent_id'].isnull()]['link_id_short'].iloc[0]\n",
    "query_original = df_example[df_example['parent_id'].isnull()]['body'].iloc[0]\n",
    "# Append responses to top query \n",
    "df_example2 = df_example[(~df_example['parent_id'].isnull()) &\n",
    "                         (df_example['body'] != '[deleted]') & \n",
    "                         (df_example['parent_id_short'].str.contains(query_id))] # get the children\n",
    "\n",
    "for resp in df_example2['body'].tolist():\n",
    "    qr_pair.append((query_original,resp))\n",
    "# Create list of ids to find children\n",
    "len(df_example2['post_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cvkbr58']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "df[(df['parent_id_short'].isin(['37o1az'])) &\n",
    "   (df['body'] != '[deleted]') # some entries have been removed for some reason\n",
    "  & (df['id'] == 'cvkbr58')]['id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryResponse:\n",
    "    \"\"\"\n",
    "    Recursive search to create query response-pairs\n",
    "    \"\"\"\n",
    "    def __init__(self,parent_id_lst):\n",
    "        self.parent_id_lst = parent_id_lst\n",
    "        #print('num parents:', len(self.parent_id_lst))\n",
    "        if type(self.parent_id_lst) == list:\n",
    "            self.children_id_lst = pd_data_frame[(pd_data_frame['parent_id_short'].isin(self.parent_id_lst)) &\n",
    "                                                 # some entries have been removed for some reason\n",
    "                                                 (pd_data_frame['body'] != '[deleted]') \n",
    "                                                ]['id'].tolist()\n",
    "        else:\n",
    "            self.children_id_lst = pd_data_frame[(pd_data_frame['parent_id_short'] == self.parent_id_lst) &\n",
    "                                                 # some entries have been removed for some reason\n",
    "                                                 (pd_data_frame['body'] != '[deleted]') \n",
    "                                                ]['id'].tolist()\n",
    "            \n",
    "        #print('num children:', len(self.children_id_lst))\n",
    "        # Given a list of parent ids, turn the cooresponding text for those into queries\n",
    "        # and the entries whose are responses to the parent_ids given...turn those into responses.\n",
    "        if type(parent_id_lst) == str:\n",
    "            parent_id_lst = [parent_id_lst]\n",
    "        query_response = []\n",
    "        count = 0\n",
    "        # for parent_id in parent_id_lst:\n",
    "        while count < len(parent_id_lst):\n",
    "            print(parent_id_lst[count])\n",
    "            query = pd_data_frame[pd_data_frame['id'] == parent_id_lst[count]]['body'].iloc[0]\n",
    "            children_ids = pd_data_frame[(pd_data_frame['parent_id_short']==parent_id_lst[count]) &\n",
    "                                              # some entries have been removed for some reason\n",
    "                                              (pd_data_frame['body'] != '[deleted]') \n",
    "                                             ]['id'].tolist()\n",
    "            for child_id in children_ids:\n",
    "                response = pd_data_frame[pd_data_frame['id'] == child_id]['body'].iloc[0]\n",
    "                query_response.append((query,response))\n",
    "            \n",
    "            count += 1\n",
    "            \n",
    "        self.query_response = query_response     \n",
    "    \n",
    "    @property\n",
    "    def child_elements(self):\n",
    "        return [QueryResponse(a) for a in self.children_id_lst]\n",
    "    \n",
    "    # Return the list of (query,response) tuples\n",
    "    @property\n",
    "    def get_value(self):\n",
    "        \n",
    "        return self.query_response\n",
    "    \n",
    "def node_recurse_generator(node):\n",
    "    \"\"\"\n",
    "    Iterates through all response/query pairs. \"node\" is a QueryResponse object.\n",
    "    \"\"\"\n",
    "    yield node.query_response\n",
    "    for n in node.child_elements:\n",
    "        yield from node_recurse_generator(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3exs68'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_threads[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3exs68\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-138-e0fbfb45b40e>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, parent_id_lst)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_id_lst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_id_lst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd_data_frame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpd_data_frame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mparent_id_lst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'body'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             children_ids = pd_data_frame[(pd_data_frame['parent_id_short']==parent_id_lst[count]) &\n\u001b[1;32m     31\u001b[0m                                               \u001b[0;31m# some entries have been removed for some reason\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google_Drive/kp_datascience/virtual_envs/nlp-env/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google_Drive/kp_datascience/virtual_envs/nlp-env/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1829\u001b[0m             \u001b[0;31m# validate the location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1830\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_valid_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1832\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google_Drive/kp_datascience/virtual_envs/nlp-env/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_is_valid_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1711\u001b[0m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1713\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1714\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Global dataframe: can be set to test or for the full dataset\n",
    "pd_data_frame = df_example\n",
    "a = QueryResponse(['3exs68'])\n",
    "test = list(node_recurse_generator(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Thank you so much! I may have something to actually update in a few days, so *fingers crossed*.',\n",
       "  'Any updates? I was surfing the top posts for the year and found this. Hoping for some answers and help for you guys. ')]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108714\n",
      "139423\n"
     ]
    }
   ],
   "source": [
    "print(len(df.post_id.unique()))\n",
    "print(len(df.id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-env",
   "language": "python",
   "name": "nlp-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
