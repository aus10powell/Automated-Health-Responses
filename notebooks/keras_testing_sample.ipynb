{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense,GRU,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_sentences(txt_str,num_words):\n",
    "    \n",
    "    return ' '.join(txt_str.lower().split(' ')[:num_words]).replace('\\n',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_response = pickle.load(open(\"../data/query_response_direct_one_sentence.p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_response_limited = []\n",
    "for (q,r) in query_response:\n",
    "    if (len(str(q).strip().split()) >= 1) and (len(str(r).strip().split()) >= 1):\n",
    "        query_response_limited.append((limit_sentences(str(q),num_words = 30),limit_sentences(str(r),num_words = 15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3999\n",
      "3925\n"
     ]
    }
   ],
   "source": [
    "print(len(query_response))\n",
    "print(len(query_response_limited))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = query_response_limited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 300\n",
      "Number of unique input tokens: 499\n",
      "Number of unique output tokens: 894\n",
      "Max sequence length for inputs: 198\n",
      "Max sequence length for outputs: 155\n",
      "CPU times: user 2.31 ms, sys: 126 Âµs, total: 2.44 ms\n",
      "Wall time: 2.47 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_size = 8  # Batch size for training.\n",
    "epochs = 100  # Number of epochs to train for.\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
    "num_samples = 300 # Number of samples to train on.\n",
    "\n",
    "\n",
    "#Vectorize the data for words\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_words = set()\n",
    "target_words = set()\n",
    "\n",
    "\n",
    "# Option 2\n",
    "for seq1, seq2 in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text = seq1, seq2\n",
    "    # We use \"tab\" as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "    target_text = '<BOS> ' + target_text + ' <EOS>' #'<BOS>' + target_text + '<EOS>'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    \n",
    "    # Only one input word\n",
    "    input_text_list = input_text.split()\n",
    "    if len(input_text_list) == 1:\n",
    "        input_words.add(input_text_list[0])\n",
    "    # Multiple input words\n",
    "    else:\n",
    "        for word in input_text_list:\n",
    "            input_words.add(word)\n",
    "                \n",
    "    # For right now we are only looking at 1 target...the medication\n",
    "    target_text_list = target_text.split()\n",
    "    for word in target_text_list:\n",
    "        target_words.add(word)\n",
    "\n",
    "# Option 2\n",
    "input_words = sorted(list(input_words))\n",
    "target_words = sorted(list(target_words))\n",
    "num_encoder_tokens = len(input_words)\n",
    "num_decoder_tokens = len(target_words)\n",
    "# set max input sequence (may need to pad...)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "print('Number of samples:', len(input_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2\n",
    "input_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(input_words)])\n",
    "target_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(target_words)])\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "\n",
    "    input_text_list = input_text.split()\n",
    "    if len(input_text_list) > 1:\n",
    "        for t, word in enumerate(input_text_list):\n",
    "            encoder_input_data[i, t, input_token_index[word]] = 1.\n",
    "    else:\n",
    "        encoder_input_data[i, t, input_token_index[input_text_list[0]]] = 1.\n",
    "    \n",
    "    target_text_list = target_text.split()\n",
    "    for t, word in enumerate(target_text_list):\n",
    "        decoder_input_data[i, t, target_token_index[word]] = 1.\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "270/270 [==============================] - 13s 50ms/step - loss: 0.3010 - val_loss: 0.2873\n",
      "Epoch 2/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.2671 - val_loss: 0.2942\n",
      "Epoch 3/100\n",
      "270/270 [==============================] - 13s 49ms/step - loss: 0.2601 - val_loss: 0.3003\n",
      "Epoch 4/100\n",
      "270/270 [==============================] - 14s 51ms/step - loss: 0.2554 - val_loss: 0.3155\n",
      "Epoch 5/100\n",
      "270/270 [==============================] - 12s 45ms/step - loss: 0.2510 - val_loss: 0.3132\n",
      "Epoch 6/100\n",
      "270/270 [==============================] - 12s 45ms/step - loss: 0.2484 - val_loss: 0.3209\n",
      "Epoch 7/100\n",
      "270/270 [==============================] - 12s 45ms/step - loss: 0.2447 - val_loss: 0.3241\n",
      "Epoch 8/100\n",
      "270/270 [==============================] - 12s 46ms/step - loss: 0.2420 - val_loss: 0.3358\n",
      "Epoch 9/100\n",
      "270/270 [==============================] - 12s 45ms/step - loss: 0.2393 - val_loss: 0.3413\n",
      "Epoch 10/100\n",
      "270/270 [==============================] - 12s 45ms/step - loss: 0.2368 - val_loss: 0.3364\n",
      "Epoch 11/100\n",
      "270/270 [==============================] - 12s 45ms/step - loss: 0.2338 - val_loss: 0.3533\n",
      "Epoch 12/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.2312 - val_loss: 0.3526\n",
      "Epoch 13/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.2294 - val_loss: 0.3639\n",
      "Epoch 14/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.2270 - val_loss: 0.3620\n",
      "Epoch 15/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.2243 - val_loss: 0.3649\n",
      "Epoch 16/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.2226 - val_loss: 0.3610\n",
      "Epoch 17/100\n",
      "270/270 [==============================] - 12s 45ms/step - loss: 0.2207 - val_loss: 0.3850\n",
      "Epoch 18/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.2183 - val_loss: 0.3805\n",
      "Epoch 19/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.2166 - val_loss: 0.3759\n",
      "Epoch 20/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.2144 - val_loss: 0.3834\n",
      "Epoch 21/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.2120 - val_loss: 0.3745\n",
      "Epoch 22/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.2096 - val_loss: 0.3772\n",
      "Epoch 23/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.2069 - val_loss: 0.3748\n",
      "Epoch 24/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.2058 - val_loss: 0.3813\n",
      "Epoch 25/100\n",
      "270/270 [==============================] - 12s 43ms/step - loss: 0.2033 - val_loss: 0.3732\n",
      "Epoch 26/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.2013 - val_loss: 0.3786\n",
      "Epoch 27/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.1980 - val_loss: 0.3801\n",
      "Epoch 28/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.1966 - val_loss: 0.3824\n",
      "Epoch 29/100\n",
      "270/270 [==============================] - 12s 43ms/step - loss: 0.1935 - val_loss: 0.3784\n",
      "Epoch 30/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.1912 - val_loss: 0.3630\n",
      "Epoch 31/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.1887 - val_loss: 0.3791\n",
      "Epoch 32/100\n",
      "270/270 [==============================] - 12s 43ms/step - loss: 0.1861 - val_loss: 0.3858\n",
      "Epoch 33/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.1833 - val_loss: 0.3840\n",
      "Epoch 34/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.1803 - val_loss: 0.3791\n",
      "Epoch 35/100\n",
      "270/270 [==============================] - 12s 43ms/step - loss: 0.1778 - val_loss: 0.3890\n",
      "Epoch 36/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.1749 - val_loss: 0.3880\n",
      "Epoch 37/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.1716 - val_loss: 0.3839\n",
      "Epoch 38/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.1686 - val_loss: 0.3883\n",
      "Epoch 39/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.1649 - val_loss: 0.3805\n",
      "Epoch 40/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.1623 - val_loss: 0.3896\n",
      "Epoch 41/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.1591 - val_loss: 0.3866\n",
      "Epoch 42/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.1551 - val_loss: 0.3895\n",
      "Epoch 43/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.1523 - val_loss: 0.3923\n",
      "Epoch 44/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.1487 - val_loss: 0.3901\n",
      "Epoch 45/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.1446 - val_loss: 0.3932\n",
      "Epoch 46/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.1414 - val_loss: 0.3964\n",
      "Epoch 47/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.1372 - val_loss: 0.3977\n",
      "Epoch 48/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.1342 - val_loss: 0.4016\n",
      "Epoch 49/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.1306 - val_loss: 0.4003\n",
      "Epoch 50/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.1263 - val_loss: 0.4017\n",
      "Epoch 51/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.1227 - val_loss: 0.4032\n",
      "Epoch 52/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.1188 - val_loss: 0.4047\n",
      "Epoch 53/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.1157 - val_loss: 0.4065\n",
      "Epoch 54/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.1113 - val_loss: 0.4056\n",
      "Epoch 55/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.1077 - val_loss: 0.4080\n",
      "Epoch 56/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.1047 - val_loss: 0.4050\n",
      "Epoch 57/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.1001 - val_loss: 0.4075\n",
      "Epoch 58/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.0972 - val_loss: 0.4100\n",
      "Epoch 59/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.0937 - val_loss: 0.4118\n",
      "Epoch 60/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.0906 - val_loss: 0.4134\n",
      "Epoch 61/100\n",
      "270/270 [==============================] - 12s 45ms/step - loss: 0.0870 - val_loss: 0.4101\n",
      "Epoch 62/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.0843 - val_loss: 0.4153\n",
      "Epoch 63/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.0806 - val_loss: 0.4187\n",
      "Epoch 64/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.0778 - val_loss: 0.4194\n",
      "Epoch 65/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.0751 - val_loss: 0.4192\n",
      "Epoch 66/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.0726 - val_loss: 0.4205\n",
      "Epoch 67/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.0702 - val_loss: 0.4233\n",
      "Epoch 68/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.0675 - val_loss: 0.4237\n",
      "Epoch 69/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.0652 - val_loss: 0.4210\n",
      "Epoch 70/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.0635 - val_loss: 0.4214\n",
      "Epoch 71/100\n",
      "270/270 [==============================] - 12s 45ms/step - loss: 0.0616 - val_loss: 0.4285\n",
      "Epoch 72/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.0601 - val_loss: 0.4263\n",
      "Epoch 73/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.0579 - val_loss: 0.4307\n",
      "Epoch 74/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.0566 - val_loss: 0.4278\n",
      "Epoch 75/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.0551 - val_loss: 0.4314\n",
      "Epoch 76/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.0538 - val_loss: 0.4329\n",
      "Epoch 77/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.0529 - val_loss: 0.4334\n",
      "Epoch 78/100\n",
      "270/270 [==============================] - 12s 45ms/step - loss: 0.0513 - val_loss: 0.4318\n",
      "Epoch 79/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.0507 - val_loss: 0.4361\n",
      "Epoch 80/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.0497 - val_loss: 0.4381\n",
      "Epoch 81/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.0489 - val_loss: 0.4388\n",
      "Epoch 82/100\n",
      "270/270 [==============================] - 12s 45ms/step - loss: 0.0484 - val_loss: 0.4347\n",
      "Epoch 83/100\n",
      "270/270 [==============================] - 12s 45ms/step - loss: 0.0473 - val_loss: 0.4403\n",
      "Epoch 84/100\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 0.0467 - val_loss: 0.4403\n",
      "Epoch 85/100\n",
      "270/270 [==============================] - 12s 45ms/step - loss: 0.0461 - val_loss: 0.4425\n",
      "Epoch 86/100\n",
      "270/270 [==============================] - 12s 45ms/step - loss: 0.0456 - val_loss: 0.4424\n",
      "Epoch 87/100\n",
      "270/270 [==============================] - 12s 45ms/step - loss: 0.0452 - val_loss: 0.4434\n",
      "Epoch 88/100\n",
      "270/270 [==============================] - 12s 45ms/step - loss: 0.0445 - val_loss: 0.4454\n",
      "Epoch 89/100\n",
      "270/270 [==============================] - 12s 45ms/step - loss: 0.0443 - val_loss: 0.4474\n",
      "Epoch 90/100\n",
      "270/270 [==============================] - 12s 45ms/step - loss: 0.0438 - val_loss: 0.4444\n",
      "Epoch 91/100\n",
      "270/270 [==============================] - 12s 45ms/step - loss: 0.0433 - val_loss: 0.4475\n",
      "Epoch 92/100\n",
      "270/270 [==============================] - 12s 45ms/step - loss: 0.0431 - val_loss: 0.4516\n",
      "Epoch 93/100\n",
      "270/270 [==============================] - 12s 45ms/step - loss: 0.0428 - val_loss: 0.4451\n",
      "Epoch 94/100\n",
      "270/270 [==============================] - 12s 45ms/step - loss: 0.0427 - val_loss: 0.4484\n",
      "Epoch 95/100\n",
      "270/270 [==============================] - 12s 45ms/step - loss: 0.0422 - val_loss: 0.4454\n",
      "Epoch 96/100\n",
      "270/270 [==============================] - 12s 45ms/step - loss: 0.0421 - val_loss: 0.4522\n",
      "Epoch 97/100\n",
      "270/270 [==============================] - 12s 45ms/step - loss: 0.0418 - val_loss: 0.4498\n",
      "Epoch 98/100\n",
      "270/270 [==============================] - 12s 45ms/step - loss: 0.0416 - val_loss: 0.4502\n",
      "Epoch 99/100\n",
      "270/270 [==============================] - 12s 45ms/step - loss: 0.0414 - val_loss: 0.4528\n",
      "Epoch 100/100\n",
      "270/270 [==============================] - 12s 45ms/step - loss: 0.0414 - val_loss: 0.4525\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1278e0588>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = GRU(latent_dim, \n",
    "              return_state=True,\n",
    "             dropout=.3)\n",
    "encoder_outputs, state_h = encoder(encoder_inputs)\n",
    "\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "decoder_gru = GRU(latent_dim, return_sequences=True)\n",
    "decoder_outputs = decoder_gru(decoder_inputs, initial_state=state_h)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "# Run training\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "270/270 [==============================] - 21s 78ms/step - loss: 0.2825 - val_loss: 0.2887\n",
      "Epoch 2/100\n",
      "270/270 [==============================] - 20s 74ms/step - loss: 0.2629 - val_loss: 0.3000\n",
      "Epoch 3/100\n",
      "270/270 [==============================] - 20s 73ms/step - loss: 0.2573 - val_loss: 0.3075\n",
      "Epoch 4/100\n",
      "270/270 [==============================] - 20s 74ms/step - loss: 0.2530 - val_loss: 0.3184\n",
      "Epoch 5/100\n",
      "270/270 [==============================] - 20s 73ms/step - loss: 0.2491 - val_loss: 0.3292\n",
      "Epoch 6/100\n",
      "270/270 [==============================] - 20s 72ms/step - loss: 0.2460 - val_loss: 0.3388\n",
      "Epoch 7/100\n",
      "270/270 [==============================] - 19s 72ms/step - loss: 0.2431 - val_loss: 0.3383\n",
      "Epoch 8/100\n",
      "270/270 [==============================] - 20s 72ms/step - loss: 0.2406 - val_loss: 0.3502\n",
      "Epoch 9/100\n",
      "270/270 [==============================] - 19s 72ms/step - loss: 0.2381 - val_loss: 0.3567\n",
      "Epoch 10/100\n",
      "270/270 [==============================] - 19s 69ms/step - loss: 0.2359 - val_loss: 0.3562\n",
      "Epoch 11/100\n",
      "270/270 [==============================] - 18s 68ms/step - loss: 0.2339 - val_loss: 0.3566\n",
      "Epoch 12/100\n",
      "270/270 [==============================] - 18s 68ms/step - loss: 0.2324 - val_loss: 0.3537\n",
      "Epoch 13/100\n",
      "270/270 [==============================] - 19s 69ms/step - loss: 0.2302 - val_loss: 0.3550\n",
      "Epoch 14/100\n",
      "270/270 [==============================] - 19s 70ms/step - loss: 0.2275 - val_loss: 0.3622\n",
      "Epoch 15/100\n",
      "270/270 [==============================] - 19s 69ms/step - loss: 0.2260 - val_loss: 0.3646\n",
      "Epoch 16/100\n",
      "270/270 [==============================] - 19s 69ms/step - loss: 0.2247 - val_loss: 0.3702\n",
      "Epoch 17/100\n",
      "270/270 [==============================] - 19s 69ms/step - loss: 0.2287 - val_loss: 0.3645\n",
      "Epoch 18/100\n",
      "270/270 [==============================] - 19s 69ms/step - loss: 0.2228 - val_loss: 0.3599\n",
      "Epoch 19/100\n",
      "270/270 [==============================] - 18s 69ms/step - loss: 0.2193 - val_loss: 0.3583\n",
      "Epoch 20/100\n",
      "270/270 [==============================] - 19s 69ms/step - loss: 0.2231 - val_loss: 0.3527\n",
      "Epoch 21/100\n",
      "270/270 [==============================] - 19s 69ms/step - loss: 0.2192 - val_loss: 0.3613\n",
      "Epoch 22/100\n",
      "270/270 [==============================] - 19s 69ms/step - loss: 0.2152 - val_loss: 0.3706\n",
      "Epoch 23/100\n",
      "270/270 [==============================] - 19s 69ms/step - loss: 0.2150 - val_loss: 0.3713\n",
      "Epoch 24/100\n",
      "270/270 [==============================] - 19s 69ms/step - loss: 0.2163 - val_loss: 0.3503\n",
      "Epoch 25/100\n",
      "270/270 [==============================] - 19s 69ms/step - loss: 0.2150 - val_loss: 0.3884\n",
      "Epoch 26/100\n",
      "270/270 [==============================] - 19s 69ms/step - loss: 0.2081 - val_loss: 0.3672\n",
      "Epoch 27/100\n",
      "270/270 [==============================] - 19s 70ms/step - loss: 0.2030 - val_loss: 0.3770\n",
      "Epoch 28/100\n",
      "270/270 [==============================] - 19s 69ms/step - loss: 0.1975 - val_loss: 0.3694\n",
      "Epoch 29/100\n",
      "270/270 [==============================] - 19s 70ms/step - loss: 0.1931 - val_loss: 0.3630\n",
      "Epoch 30/100\n",
      "270/270 [==============================] - 19s 70ms/step - loss: 0.1883 - val_loss: 0.3724\n",
      "Epoch 31/100\n",
      "270/270 [==============================] - 19s 69ms/step - loss: 0.1841 - val_loss: 0.3760\n",
      "Epoch 32/100\n",
      "270/270 [==============================] - 19s 69ms/step - loss: 0.1790 - val_loss: 0.3677\n",
      "Epoch 33/100\n",
      "270/270 [==============================] - 19s 70ms/step - loss: 0.1738 - val_loss: 0.3782\n",
      "Epoch 34/100\n",
      "270/270 [==============================] - 19s 69ms/step - loss: 0.1685 - val_loss: 0.3713\n",
      "Epoch 35/100\n",
      "270/270 [==============================] - 19s 69ms/step - loss: 0.1636 - val_loss: 0.3794\n",
      "Epoch 36/100\n",
      "270/270 [==============================] - 19s 69ms/step - loss: 0.1581 - val_loss: 0.3762\n",
      "Epoch 37/100\n",
      "270/270 [==============================] - 19s 69ms/step - loss: 0.1521 - val_loss: 0.3721\n",
      "Epoch 38/100\n",
      "270/270 [==============================] - 19s 70ms/step - loss: 0.1470 - val_loss: 0.3776\n",
      "Epoch 39/100\n",
      "270/270 [==============================] - 19s 71ms/step - loss: 0.1422 - val_loss: 0.3756\n",
      "Epoch 40/100\n",
      "270/270 [==============================] - 19s 69ms/step - loss: 0.1359 - val_loss: 0.3825\n",
      "Epoch 41/100\n",
      "270/270 [==============================] - 19s 70ms/step - loss: 0.1309 - val_loss: 0.3848\n",
      "Epoch 42/100\n",
      "270/270 [==============================] - 19s 70ms/step - loss: 0.1256 - val_loss: 0.3769\n",
      "Epoch 43/100\n",
      "270/270 [==============================] - 19s 69ms/step - loss: 0.1211 - val_loss: 0.3778\n",
      "Epoch 44/100\n",
      "270/270 [==============================] - 20s 72ms/step - loss: 0.1159 - val_loss: 0.3842\n",
      "Epoch 45/100\n",
      "270/270 [==============================] - 21s 76ms/step - loss: 0.1118 - val_loss: 0.3875\n",
      "Epoch 46/100\n",
      "270/270 [==============================] - 20s 75ms/step - loss: 0.1069 - val_loss: 0.4019\n",
      "Epoch 47/100\n",
      "270/270 [==============================] - 19s 70ms/step - loss: 0.1029 - val_loss: 0.3977\n",
      "Epoch 48/100\n",
      "270/270 [==============================] - 19s 70ms/step - loss: 0.0985 - val_loss: 0.3940\n",
      "Epoch 49/100\n",
      "270/270 [==============================] - 19s 70ms/step - loss: 0.0956 - val_loss: 0.3925\n",
      "Epoch 50/100\n",
      "270/270 [==============================] - 19s 70ms/step - loss: 0.0930 - val_loss: 0.4083\n",
      "Epoch 51/100\n",
      "270/270 [==============================] - 20s 73ms/step - loss: 0.0889 - val_loss: 0.3979\n",
      "Epoch 52/100\n",
      "270/270 [==============================] - 20s 73ms/step - loss: 0.0853 - val_loss: 0.4088\n",
      "Epoch 53/100\n",
      "270/270 [==============================] - 20s 73ms/step - loss: 0.0827 - val_loss: 0.3979\n",
      "Epoch 54/100\n",
      "270/270 [==============================] - 21s 78ms/step - loss: 0.0800 - val_loss: 0.4028\n",
      "Epoch 55/100\n",
      "270/270 [==============================] - 21s 77ms/step - loss: 0.0773 - val_loss: 0.4044\n",
      "Epoch 56/100\n",
      "270/270 [==============================] - 20s 72ms/step - loss: 0.0751 - val_loss: 0.4045\n",
      "Epoch 57/100\n",
      "270/270 [==============================] - 21s 78ms/step - loss: 0.0732 - val_loss: 0.4126\n",
      "Epoch 58/100\n",
      "270/270 [==============================] - 20s 74ms/step - loss: 0.0703 - val_loss: 0.4113\n",
      "Epoch 59/100\n",
      "270/270 [==============================] - 20s 72ms/step - loss: 0.0691 - val_loss: 0.4122\n",
      "Epoch 60/100\n",
      "270/270 [==============================] - 21s 80ms/step - loss: 0.0669 - val_loss: 0.4133\n",
      "Epoch 61/100\n",
      "270/270 [==============================] - 21s 79ms/step - loss: 0.0645 - val_loss: 0.4078\n",
      "Epoch 62/100\n",
      "270/270 [==============================] - 22s 83ms/step - loss: 0.0630 - val_loss: 0.4118\n",
      "Epoch 63/100\n",
      "270/270 [==============================] - 24s 87ms/step - loss: 0.0615 - val_loss: 0.4130\n",
      "Epoch 64/100\n",
      "270/270 [==============================] - 22s 81ms/step - loss: 0.0601 - val_loss: 0.4133\n",
      "Epoch 65/100\n",
      "270/270 [==============================] - 23s 86ms/step - loss: 0.0630 - val_loss: 0.4149\n",
      "Epoch 66/100\n",
      "270/270 [==============================] - 21s 79ms/step - loss: 0.0924 - val_loss: 0.3908\n",
      "Epoch 67/100\n",
      "270/270 [==============================] - 22s 83ms/step - loss: 0.0640 - val_loss: 0.4217\n",
      "Epoch 68/100\n",
      "270/270 [==============================] - 22s 81ms/step - loss: 0.0569 - val_loss: 0.4207\n",
      "Epoch 69/100\n",
      "270/270 [==============================] - 22s 80ms/step - loss: 0.0545 - val_loss: 0.4203\n",
      "Epoch 70/100\n",
      "270/270 [==============================] - 22s 82ms/step - loss: 0.0546 - val_loss: 0.4209\n",
      "Epoch 71/100\n",
      "270/270 [==============================] - 21s 77ms/step - loss: 0.0529 - val_loss: 0.4193\n",
      "Epoch 72/100\n",
      "270/270 [==============================] - 21s 77ms/step - loss: 0.0513 - val_loss: 0.4198\n",
      "Epoch 73/100\n",
      "270/270 [==============================] - 21s 80ms/step - loss: 0.0505 - val_loss: 0.4204\n",
      "Epoch 74/100\n",
      "270/270 [==============================] - 22s 80ms/step - loss: 0.0498 - val_loss: 0.4190\n",
      "Epoch 75/100\n",
      "270/270 [==============================] - 21s 77ms/step - loss: 0.0490 - val_loss: 0.4300\n",
      "Epoch 76/100\n",
      "270/270 [==============================] - 21s 77ms/step - loss: 0.0482 - val_loss: 0.4207\n",
      "Epoch 77/100\n",
      "270/270 [==============================] - 24s 88ms/step - loss: 0.0477 - val_loss: 0.4253\n",
      "Epoch 78/100\n",
      "270/270 [==============================] - 22s 83ms/step - loss: 0.0472 - val_loss: 0.4247\n",
      "Epoch 79/100\n",
      "270/270 [==============================] - 23s 83ms/step - loss: 0.0536 - val_loss: 0.4129\n",
      "Epoch 80/100\n",
      "270/270 [==============================] - 24s 90ms/step - loss: 0.0496 - val_loss: 0.4214\n",
      "Epoch 81/100\n",
      "270/270 [==============================] - 22s 81ms/step - loss: 0.0470 - val_loss: 0.4249\n",
      "Epoch 82/100\n",
      "270/270 [==============================] - 24s 89ms/step - loss: 0.0464 - val_loss: 0.4225\n",
      "Epoch 83/100\n",
      "270/270 [==============================] - 23s 85ms/step - loss: 0.0451 - val_loss: 0.4215\n",
      "Epoch 84/100\n",
      "270/270 [==============================] - 23s 86ms/step - loss: 0.0446 - val_loss: 0.4234\n",
      "Epoch 85/100\n",
      "270/270 [==============================] - 23s 84ms/step - loss: 0.0441 - val_loss: 0.4276\n",
      "Epoch 86/100\n",
      "270/270 [==============================] - 22s 81ms/step - loss: 0.0436 - val_loss: 0.4294\n",
      "Epoch 87/100\n",
      "270/270 [==============================] - 21s 79ms/step - loss: 0.0434 - val_loss: 0.4340\n",
      "Epoch 88/100\n",
      "270/270 [==============================] - 21s 79ms/step - loss: 0.0429 - val_loss: 0.4235\n",
      "Epoch 89/100\n",
      "270/270 [==============================] - 21s 78ms/step - loss: 0.0427 - val_loss: 0.4275\n",
      "Epoch 90/100\n",
      "270/270 [==============================] - 21s 78ms/step - loss: 0.0427 - val_loss: 0.4282\n",
      "Epoch 91/100\n",
      "270/270 [==============================] - 21s 79ms/step - loss: 0.0419 - val_loss: 0.4317\n",
      "Epoch 92/100\n",
      "270/270 [==============================] - 22s 80ms/step - loss: 0.0418 - val_loss: 0.4282\n",
      "Epoch 93/100\n",
      "270/270 [==============================] - 22s 81ms/step - loss: 0.0417 - val_loss: 0.4297\n",
      "Epoch 94/100\n",
      "270/270 [==============================] - 25s 93ms/step - loss: 0.0415 - val_loss: 0.4215\n",
      "Epoch 95/100\n",
      "270/270 [==============================] - 23s 84ms/step - loss: 0.0411 - val_loss: 0.4302\n",
      "Epoch 96/100\n",
      "270/270 [==============================] - 23s 84ms/step - loss: 0.0410 - val_loss: 0.4359\n",
      "Epoch 97/100\n",
      "270/270 [==============================] - 22s 83ms/step - loss: 0.0410 - val_loss: 0.4337\n",
      "Epoch 98/100\n",
      "270/270 [==============================] - 23s 86ms/step - loss: 0.0407 - val_loss: 0.4353\n",
      "Epoch 99/100\n",
      "270/270 [==============================] - 23s 83ms/step - loss: 0.0406 - val_loss: 0.4310\n",
      "Epoch 100/100\n",
      "270/270 [==============================] - 22s 83ms/step - loss: 0.0404 - val_loss: 0.4344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13d9d9d30>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True,dropout=.1,recurrent_dropout=0.1)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the \n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "# Run training\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(model.history.history['loss'])\n",
    "plt.plot(model.history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) encode input and retrieve initial decoder state\n",
    "# 2) run one step of decoder with this initial state\n",
    "# and a \"start of sequence\" token as target.\n",
    "# Output will be the next target token\n",
    "# 3) Repeat with the current target token and current states\n",
    "\n",
    "# Define sampling models\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "(i, char) for char, i in target_token_index.items())\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first word of target sequence with the start word.\n",
    "    target_seq[0, 0, target_token_index['<BOS>']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += ' ' + sampled_char\n",
    "        #print('decoded_sentence internal',decoded_sentence)\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            #print(\"sample char {}\".format(sampled_char))\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence.replace('<EOS>','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: pertinent fact\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: pertinent fact\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: pertinent fact\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: pertinent fact\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: pertinent fact\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: pertinent fact\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: pertinent fact\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: pertinent fact\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: pertinent fact\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: pertinent fact\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: pertinent fact\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: pertinent fact\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: pertinent fact\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: pertinent fact\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: pertinent fact\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: pertinent fact\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: pertinent fact\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: pertinent fact\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: hi reddit 24 european male mri scan ent find little parotid week ago\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: hi reddit 24 european male mri scan ent find little parotid week ago\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: hello\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: not sure medical stuff need eye relate question female 20 s no preexist condition eye stuff wear glass 20 year\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: 28 m 6 140lbs caucasian\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: 28 m 6 140lbs caucasian\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: -pron- didn t give paper gastritis\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: -pron- didn t give paper gastritis\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: so -pron- m gather people chronic pain have problem get opiod doctor neglect prescribe\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: so -pron- m gather people chronic pain have problem get opiod doctor neglect prescribe\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: so -pron- m gather people chronic pain have problem get opiod doctor neglect prescribe\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: so -pron- m gather people chronic pain have problem get opiod doctor neglect prescribe\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: so -pron- m gather people chronic pain have problem get opiod doctor neglect prescribe\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: so -pron- m gather people chronic pain have problem get opiod doctor neglect prescribe\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: so -pron- m gather people chronic pain have problem get opiod doctor neglect prescribe\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: -pron- m 55yearold male nonsmoker nondrinker reasonably healthy diet lot plant base limit fatty food\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: -pron- m 55yearold male nonsmoker nondrinker reasonably healthy diet lot plant base limit fatty food\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: -pron- m 55yearold male nonsmoker nondrinker reasonably healthy diet lot plant base limit fatty food\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: -pron- m 55yearold male nonsmoker nondrinker reasonably healthy diet lot plant base limit fatty food\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: hello -pron- ve suffer occipital neuralgia past 5 ish year diagnose summer\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: hello -pron- ve suffer occipital neuralgia past 5 ish year diagnose summer\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: hello\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: hello\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: hello\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: hello\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: so -pron- ve mild sore throat 4 day\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: hi age 27 sex male height 5 10 weight 180\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: hi age 27 sex male height 5 10 weight 180\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: hi age 27 sex male height 5 10 weight 180\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: this go month happen occasion happen doesn t usually last day\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: this go month happen occasion happen doesn t usually last day\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: age 72 sex female height 165 cm\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: age 72 sex female height 165 cm\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: hi -pron- m begin second month training muay thai local gym\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: hi -pron- m begin second month training muay thai local gym\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: hi -pron- m begin second month training muay thai local gym\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: here s story\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: here s story\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: hi 30 year old caucasian male 140 lb 5 10 nyc\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: 20\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: 20\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: 20\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: 20\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: 20\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: 20\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: 20\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: -pron- state maryland medical marijuana\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: -pron- state maryland medical marijuana\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: -pron- state maryland medical marijuana\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: -pron- state maryland medical marijuana\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: -pron- cut finger night chop vegetable\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: -pron- cut finger night chop vegetable\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: -pron- cut finger night chop vegetable\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: -pron- brief conversation uncle s doctor differently pain feel cut finger compare let tumor grow pancreatic duct kidney stone sort\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: hello\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: hello\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: -pron- recent graduate us university\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: -pron- recent graduate us university\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: -pron- recent graduate us university\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: -pron- recent graduate us university\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: -pron- recent graduate us university\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: -pron- recent graduate us university\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: not list specific -pron- m look remedy specific ailment\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: not list specific -pron- m look remedy specific ailment\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: 21 female\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: 21 female\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: 21 female\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: 21 female\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: hello -pron- 18 year old male -pron- sick small fever 5 day ago\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: hello -pron- 18 year old male -pron- sick small fever 5 day ago\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: age 32\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: age 32\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: age 32\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: hey guy\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: hey guy\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: hey guy\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: recently cold -pron- persistent dry cough long cold go\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: recently cold -pron- persistent dry cough long cold go\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: recently cold -pron- persistent dry cough long cold go\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: recently cold -pron- persistent dry cough long cold go\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: 34 f 5 7 130ish pound white\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n",
      "-\n",
      "Input sentence: 28 female 5 4\n",
      "Decoded sentence:  -pron- m doctor thing happen january    right m                \n"
     ]
    }
   ],
   "source": [
    "# Option 1\n",
    "for seq_index in range(100):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    target_seq =decoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-env",
   "language": "python",
   "name": "nlp-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
