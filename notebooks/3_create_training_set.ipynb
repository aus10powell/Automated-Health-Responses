{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scope\n",
    "\n",
    "This notebook goes through how to create a training set from a set of questions and answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import math\n",
    "import sys\n",
    "import pickle\n",
    "import glob\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Custom libraries\n",
    "# from seq2seq_model import Seq2SeqModel\n",
    "# from corpora_tools import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'author': 'RissaWasTaken', 'reader': 'kql', 'utterance': 'Husband deteriorating before my eyes, doctors at a loss, no one will help; Reddit docs, I need you.'} {'author': 'kql', 'reader': 'RissaWasTaken', 'utterance': \"Hey, how's your husband doing now? Hope everything is okay.\"}\n",
      "\n",
      "{'author': 'RissaWasTaken', 'reader': 'kql', 'utterance': 'Husband deteriorating before my eyes, doctors at a loss, no one will help; Reddit docs, I need you.'} {'author': 'kql', 'reader': 'RissaWasTaken', 'utterance': \"I really do wish the best for your husband and hope you eventually get through this! keep your and your husband's head up and tell him he has people cheering for him sure, including me! :)\"}\n",
      "\n",
      "{'author': 'RissaWasTaken', 'reader': 'BrownIRL', 'utterance': 'Husband deteriorating before my eyes, doctors at a loss, no one will help; Reddit docs, I need you.'} {'author': 'BrownIRL', 'reader': 'RissaWasTaken', 'utterance': \"A few weeks ago I was suffering from the same symptoms. Severe groin pain that radiated through my testicles and legs, urgent urination even though I didn't need to pee, muscle twitching/eye twitching. Everything came back normal. When I went to the hospital the sixth time, the doctors found that I had a lot of poop stuck in my colon around the pelvis area so they gave me an enema and some miralax and I was instantly cured. all this pain was also giving me anxiety and the anxiety made me feel like my face was going numb and that my legs and arms were going numb. After a few days I was still having trouble sleeping but I'm getting back to normal now. Poop is no joke and I hope that this is the problem your husband is having! If not.... I'm honestly so sorry because having to go through this pain for sooooooo long is insanely depressing. Maybe check out this subreddit /r/chronicpain\"}\n",
      "\n",
      "{'author': 'RissaWasTaken', 'reader': 'Tusitleal', 'utterance': 'Husband deteriorating before my eyes, doctors at a loss, no one will help; Reddit docs, I need you.'} {'author': 'Tusitleal', 'reader': 'RissaWasTaken', 'utterance': 'remind me! one day\\n'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Option 1: All responses are equal to the original query except for the comment by the author\n",
    "# Zipped Q/A\n",
    "data = pickle.load(open('../data/all_responses_equal.p','rb'))\n",
    "for i,j in list(data)[:4]:\n",
    "    print(i,j)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retrieve_cornell_corpora' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6d9f26efa0ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msen_l1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msen_l2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretrieve_cornell_corpora\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"# Two consecutive sentences in a conversation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Q:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msen_l1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"A:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msen_l2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"# Corpora length (i.e. number of sentences)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'retrieve_cornell_corpora' is not defined"
     ]
    }
   ],
   "source": [
    "sen_l1, sen_l2 = retrieve_cornell_corpora()\n",
    "print(\"# Two consecutive sentences in a conversation\")\n",
    "print(\"Q:\", sen_l1[0])\n",
    "print(\"A:\", sen_l2[0])\n",
    "print(\"# Corpora length (i.e. number of sentences)\")\n",
    "print(len(sen_l1))\n",
    "assert len(sen_l1) == len(sen_l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Trainable dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenized_sequencial_sentences(list_of_lines, line_text):\n",
    "    for line in list_of_lines:\n",
    "        for i in range(len(line) - 1):\n",
    "            yield (line_text[line[i]].split(\" \"), line_text[line[i+1]].split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_cornell_corpora(storage_path=\"/tmp\", storage_dir=\"cornell_movie_dialogs_corpus\"):\n",
    "   download_and_decompress(\"http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\",      \n",
    "                     storage_path,\n",
    "                           storage_dir)\n",
    "   conversations = read_conversations(storage_path, storage_dir)\n",
    "   lines = read_lines(storage_path, storage_dir)\n",
    "   return tuple(zip(*list(get_tokenized_sequencial_sentences(conversations, lines))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_sen_l1 = [clean_sentence(s) for s in sen_l1]\n",
    "clean_sen_l2 = [clean_sentence(s) for s in sen_l2]\n",
    "filt_clean_sen_l1, filt_clean_sen_l2 = filter_sentence_length(clean_sen_l1, clean_sen_l2)\n",
    "print(\"# Filtered Corpora length (i.e. number of sentences)\")\n",
    "print(len(filt_clean_sen_l1))\n",
    "assert len(filt_clean_sen_l1) == len(filt_clean_sen_l2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-env",
   "language": "python",
   "name": "nlp-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
