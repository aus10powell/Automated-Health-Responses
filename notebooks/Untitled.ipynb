{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense,GRU,Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using from 2 sites:\n",
    "*Main: https://machinelearningmastery.com/develop-encoder-decoder-model-sequence-sequence-prediction-keras/\n",
    "*Second https://stackoverflow.com/questions/49477097/keras-seq2seq-word-embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_sentences(txt_str,num_words):\n",
    "    \n",
    "    return ' '.join(txt_str.lower().split(' ')[:num_words]).replace('\\n',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96112\n"
     ]
    }
   ],
   "source": [
    "query_response = pickle.load(open(\"../data/query_response_direct.p\",\"rb\"))\n",
    "print(len(query_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pertinent fact', 'hey s husband'),\n",
       " ('pertinent fact', 'a week ago -PRON- suffer symptom'),\n",
       " ('pertinent fact',\n",
       "  'hi op sure mention worth travel big hospital like university doctor work use chart lab etc'),\n",
       " ('pertinent fact', '1'),\n",
       " ('pertinent fact', '-PRON- heart go husband'),\n",
       " ('pertinent fact', 'any update'),\n",
       " ('pertinent fact',\n",
       "  'with medical professional able diagnose husband reddit s audience unable possibility livein boyfriend poison husband'),\n",
       " ('pertinent fact',\n",
       "  'with kind extensive diagnostic finding -PRON- suggest psychiatric referral'),\n",
       " ('pertinent fact', '-PRON- m sorry go'),\n",
       " ('pertinent fact', 'how'),\n",
       " ('pertinent fact',\n",
       "  'https www google com url sa t amp source web amp rct j amp ei kjgzvfbhh8trtqwlnqviaw amp url http www nlm nih gov medlineplus magazine issue spring11 article spring11pg1011 html amp v 0cciqfjac amp usg afqjcnh3ay nkv4kiez2jk0 rlu1k28skq amp sig2 b2q2mnklagtbdujjyfmyyw'),\n",
       " ('pertinent fact',\n",
       "  'an infection spread bladder kidney antibiotic cure possibly hide prostate'),\n",
       " ('pertinent fact', 'not doctor parent nurse'),\n",
       " ('pertinent fact', '-PRON- doctor'),\n",
       " ('pertinent fact', 'how s'),\n",
       " ('pertinent fact', 'not doctor be brain mri'),\n",
       " ('pertinent fact', 'have husband lyme disease'),\n",
       " ('pertinent fact', 'any update'),\n",
       " ('hi reddit 24 european male mri scan ent find little parotid week ago',\n",
       "  'hi'),\n",
       " ('hi reddit 24 european male mri scan ent find little parotid week ago',\n",
       "  '-PRON- need superficial parotidectomy'),\n",
       " ('hello', 'hey man'),\n",
       " ('not sure medical stuff need eye relate question female 20 s no preexist condition eye stuff wear glass 20 year',\n",
       "  'do happen time blink'),\n",
       " ('28 m 6 140lbs caucasian', 'similar situation week ago virus strep mean'),\n",
       " ('28 m 6 140lbs caucasian', 'if strep bacterial because like actinomyce'),\n",
       " ('-PRON- didn t give paper gastritis', 'any luck symptom'),\n",
       " ('-PRON- didn t give paper gastritis',\n",
       "  'sound like workup underway take biopsy need processing time'),\n",
       " ('so -PRON- m gather people chronic pain have problem get opiod doctor neglect prescribe',\n",
       "  'okay'),\n",
       " ('so -PRON- m gather people chronic pain have problem get opiod doctor neglect prescribe',\n",
       "  'pain medication addictive abuse'),\n",
       " ('so -PRON- m gather people chronic pain have problem get opiod doctor neglect prescribe',\n",
       "  '-PRON- doctor refuse opiate reason addiction actually chronic pain bad'),\n",
       " ('so -PRON- m gather people chronic pain have problem get opiod doctor neglect prescribe',\n",
       "  'http abcnew com us prescriptionpainkillersrecordnumberamericanspainmedication story would 13421828because use way people perceive need med need end turn dependency addiction')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_response[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(sentenceLength,), name=\"Encoder_input\")\n",
    "encoder = LSTM(n_units, return_state=True, name='Encoder_lstm') \n",
    "Shared_Embedding = Embedding(output_dim=embedding, input_dim=vocab_size, name=\"Embedding\") \n",
    "word_embedding_context = Shared_Embedding(encoder_inputs) \n",
    "encoder_outputs, state_h, state_c = encoder(word_embedding_context) \n",
    "encoder_states = [state_h, state_c] decoder_lstm = LSTM(n_units, return_sequences=True, return_state=True, name=\"Decoder_lstm\") \n",
    "word_embedding_answer = Shared_Embedding(decoder_inputs) decoder_outputs, _, _ = decoder_lstm(word_embedding_answer, initial_state=encoder_states) \n",
    "decoder_dense = Dense(vocab_size, activation='softmax', name=\"Dense_layer\") \n",
    "decoder_outputs = decoder_dense(decoder_outputs) \n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
    "encoder_model = Model(encoder_inputs, encoder_states) \n",
    "decoder_state_input_h = Input(shape=(n_units,), name=\"H_state_input\") \n",
    "decoder_state_input_c = Input(shape=(n_units,), name=\"C_state_input\") \n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c] \n",
    "decoder_outputs, state_h, state_c = decoder_lstm(word_embedding_answer, initial_state=decoder_states_inputs) \n",
    "decoder_states = [state_h, state_c] \n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-env",
   "language": "python",
   "name": "nlp-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
